![Getting Started with a Movie Recommendation System](/images/movie/movie0.jpeg)

This project focuses on movie recommendation systems using the TMDB 5000 movie dataset.

# Table of Contents
1. [Chapter 1 - Project Overview](#ch1)
1. [Chapter 2 - Types of recommendation systems](#ch2)
1. [Chapter 3 - Step 1: Data Gathering](#ch3)
1. [Chapter 4 - Step 2: Demographic Filtering](#ch4)
1. [Chapter 5 - Step 3: Content Based Filtering](#ch5)
1. [Chapter 6 - Step 4: Collaborative Filtering](#ch6)
1. [References](#ch90)


<a id="ch1"></a>
# Project Overview

The growing number of data collections is leading to a new era of information. Data is used to build better systems, and this is where recommendation systems come into play. Recommendation systems are a type of information filtering systems because they improve the quality of search results and provide items that are more relevant or related to the search item or search history of the user.

Almost every major tech company uses them in one form or another: Amazon uses them to suggest products to customers, YouTube uses them to decide which video to play next on autoplay, and Facebook uses them to recommend pages. Moreover, companies like Netflix and Spotify depend heavily on the effectiveness of their recommendation systems for their business and success.

<a id="ch2"></a>
# Types of recommendation systems

There are basically three types of recommender systems:

- Demographic Filtering- Netflix offers recommendations to every user, based on what movies are popular or in a specific genre. The System recommends similar movies to users who have similar demographic features. Since each person is different, this approach is considered to be too simplistic.The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.

- Content Based Filtering- They suggest similar items based on the item that one has selected. This system uses metadata about items, such as genre, director, description, and actors. The basic idea behind these recommender systems is that if someone likes an item, they're likely to like other items similar to it.

- Collaborative Filtering- This system matches people with similar interests and provides recommendations based on this matching. Collaborative filters don't require metadata like content-based filters do.

<a id="ch3"></a>
# Step 1: Data Gathering and info from Kaggle

# About Dataset
What can we say about the success of a movie before it is released? Do you have a consistent formula for making decisions? Given that big-budget films can still fail, this question is more important than ever to the movie industry. Movie fans may have different interests, so can we anticipate which films will be highly rated, whether they are commercial successes or not?

This is a great place to start digging into those questions, with data on the plot, cast, crew, budget, and revenues of several thousand films.

# Data Sets

The dataset for this project can be found on the Kaggle website or using the Kaggle app in Python. I chose the second option. 

I worked with the following datasets: tmdb_5000_credits.csv and tmdb_5000_movies.csv  

The first dataset contains the following features:

- movie_id - A unique identifier for each movie.
- cast - The name of lead and supporting actors.
- crew - The name of Director, Editor, Composer, Writer etc.

The second dataset has the following features:

- budget - The budget in which the movie was made.
- genre - The genre of the movie, Action, Comedy ,Thriller etc.
- homepage - A link to the homepage of the movie.
- id - This is infact the movie_id as in the first dataset.
- keywords - The keywords or tags related to the movie.
- original_language - The language in which the movie was made.
- original_title - The title of the movie before translation or adaptation.
- overview - A brief description of the movie.
- popularity - A numeric quantity specifying the movie popularity.
- production_companies - The production house of the movie.
- production_countries - The country in which it was produced.
- release_date - The date on which it was released.
- revenue - The worldwide revenue generated by the movie.
- runtime - The running time of the movie in minutes.
- status - "Released" or "Rumored".
- tagline - Movie's tagline.
- title - Title of the movie.
- vote_average - average ratings the movie recieved.
- vote_count - the count of votes recieved.

I joined the two datasets on the 'id' column.

```
df1.columns = ['id','tittle','cast','crew']
df2= df2.merge(df1,on='id')
```

Take a look at the data: 
```
df2.head(10)
```
![First look at the data](/images/movie/movie1.jpg)

I found [this paper](https://www.ijert.org/research/recommender-systems-types-of-filtering-techniques-IJERTV3IS110197.pdf) that was helpful in understanding recommendations systems and the filtering techniques. Then I looked into three filtering techniques:

![Filtering Techniques](/images/movie/movie2.jpg)


<a id="ch4"></a>
# Step 2: Demographic Filtering

Demographic filtering (DF) is a process of categorizing people and recommending services based on their demographic information. DF user profiles are built by grouping individuals into archetypes that describe the common characteristics of different user groups. [This paper](https://link.springer.com/article/10.1023/A:1022850703159) provides further information about DF. DF is a service that is used by semi-trusted third parties to recommend services to specific consumers based on data about them.

DF tracks customer buying behavior across different categories, and groups customers with similar demographic traits into groups. For a new user, suggestions are generated by first determining which category he belongs to, and then applying the cumulative purchasing preferences of prior users to that category.The Demographic approach does not require a history of user ratings unlike collaborative and content-based techniques.

We need a way to score or rate a movie, calculate the score for each movie, and order the scores. We also need a way to propose the highest rated movie to users. Therefore, I'll use IMDB's weighted rating (wr), which is as follows:

![IMDB's weighted rating (wr)](/images/movie/movie3.jpg)

Where v is the total number of votes for the movie. The number of votes required to be included in the chart is m. The movie's rating is R and the average vote for the entire report is C.

We already have v (number of votes) and R (average number of votes), so C is calculated simply:

```
C= df2['vote_average'].mean()
C
```

6.092171559442011

The average rating for all of the movies is around a 6 on a scale of 10. The next step is to choose an appropriate value for m, which is the number of votes needed to be included in the chart. We will choose the 90th percentile as our cutoff. In other words, a movie needs to get more votes than at least 90% of the other movies on the list in order to be included in the chart.

```
m= df2['vote_count'].quantile(0.9)
m
```

1838.4000000000015

We can now filter the movies that are eligible for the chart.

```
q_movies = df2.copy().loc[df2['vote_count'] >= m]
q_movies.shape
```

(481, 26)

There are a total of 481 movies that meet the criteria for inclusion in this list. We will need to determine a metric to measure each qualified movie. We'll create a weighted rating() function to calculate the value of a new feature score, which will be applied to our DataFrame of qualified movies.

```
def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    return (v/(v+m) * R) + (m/(m+v) * C)
```

Create a new feature called "score" and calculate its value using the "weighted_rating()" function.

```
q_movies['score'] = q_movies.apply(weighted_rating, axis=1)
```

Then, sort the DataFrame by the score feature and output the top 15 movies' title, vote count, vote average, and weighted rating or score. The index has been reset:

```
q_movies = q_movies.sort_values('score', ascending=False)
q_movies[['title', 'vote_count', 'vote_average', 'score']].head(15)
```
![Top 15 movies](/images/movie/movie4.jpg)

We've made a recommendation for the first time. We can identify movies that are very popular right now on these systems, and we can find them by sorting the dataset by the popularity column.

```
pop= df2.sort_values('popularity', ascending=False)
import matplotlib.pyplot as plt
plt.figure(figsize=(12,4))

plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',
        color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Popular Movies")
```

![Popular movies](/images/movie/movie5.jpg)

Please note that these demographic recommender systems recommend all users with a generic chart of recommended movies. They do not care about what the user wants or prefers. We may be able to fix this issue when we switch to a more advanced system called content-based filtering.

<a id="ch5"></a>
# Step 3: Content Based Filtering

![Content Based Filtering](/images/movie/movie6.jpg)

Content-based filtering makes recommendations based on user preferences for product features. Content-based filtering is an important area of research that continues to develop and expand. It is considered to be the continuation of information fromÂ filtering research: [Belkin et al.'s paper](https://dl.acm.org/doi/abs/10.1145/138859.138861). 

In a CBF system, objects of interest are defined by their associated features. Text recommendation systems, such as newsgroup filtering systems, use words in the text as features.The content-based recommender builds a profile of user interests based on the features contained in the objects rated by the user, known as "item-to-item relevance", which determines the type of user profile based on the learning method used. Decision trees, neural nets, and vector-based representations have all been used in decision-making.

[In a study of Web documents](https://www.aaai.org/Papers/Symposia/Spring/1996/SS-96-05/SS96-05-010.pdf), users assign a value to each one on a two-point scale, with "hot" representing a high value and "cold" representing a low value. These ratings are then used to determine the likelihood of words appearing in hot or cold documents based on user ratings.Then there is WebWatcher, which monitors user actions and link selections on web pages to recommend links on web pages that the user may visit in the future. Unlike collaborative filtering, the CBF is not as complicated because all that is required is an analysis of the things that an independent user has purchased or seen.

* Plot description based Recommender

Based on plot descriptions, I analyzed pairwise similarity scores between all movies and made recommendations based on those values. The dataset's overview feature includes a plot explanation that provides additional detail about the data. Let's take a closer look at the data:

```
df2['overview'].head(10)
```
![plot descriptions](/images/movie/movie7.jpg)

To understand what the text is about, we look for words that are commonly used. Term frequency measures how often a particular word or phrase appears in a text. Luckily, the scikit-learn library provides a built-in TfIdfVectorizer class that can produce a TF-IDF matrix in a few lines of code. However more info on TF-IDF can be seen here: [A Gentle Introduction To Calculating The TF-IDF Values](https://towardsdatascience.com/a-gentle-introduction-to-calculating-the-tf-idf-values-9e391f8a13e5)

```
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')

df2['overview'] = df2['overview'].fillna('')

tfidf_matrix = tfidf.fit_transform(df2['overview'])

tfidf_matrix.shape
```

(4803, 20978)

We found that the 4800 movies in our dataset were described with over 20,000 different words. We can now compute a similarity score using this matrix. There are three possible similarity scores for this: the euclidean, Pearson, and cosine scores. There is no "right" answer when it comes to which score is the best.Different scores work well in different situations, so it's a good idea to experiment with different measures.

A numerical value will be created that represents the similarity between two movies. We use the cosine similarity score because it is independent of magnitude and is reasonably simple and quick to calculate. 

The dot product calculation gave me the cosine similarity score because I used the TF-IDF vectorizer. As a result, I implemented linear kernel() from sklearn instead of cosine similarity() because it's quicker.

```
from sklearn.metrics.pairwise import linear_kernel

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
```

After further processing the data, I was able to find the index of a movie by its title, get a list of cosine similarity ratings for that movie compared to all other movies. Then, convert it to a tuple list, where the first element is the position and the second is the similarity value. Then sort the  list of tuples based on the similarity scores. Followed by noting the top ten items on this list.I ignored the first element because it's about the self (the movie most similar to a particular movie is the movie itself). I then found the titles that correspond to the top elements' indices.

Let's check out the results for the movies 'Inception' and 'The Godfather':

```
get_recommendations('Inception')
```

![get_recommendations('Inception')](/images/movie/movie8.jpg)


```
get_recommendations('The Godfather')
```

![get_recommendations('The Godfather')](/images/movie/movie9.jpg)

Our system was able to locate similar movies with plot descriptions, but the quality of the recommendations wasn't great. Better metadata can help improve the quality of our recommender system. That is exactly what I did in this part. The data used to generate a recommender for movie viewers was the top three actors, the director, relative genres and narrative keywords.

I needed to extract the three most important actors, directors, and keywords related to the movie from the cast, crew, and keyword features. Our data is currently stored in a format that I need to change into a more secure and usable structure. After that, I developed functions to help me extract the essential data from each feature.

![Actors, directors, and keywords](/images/movie/movie10.jpg)

The names and keyword instances were then converted to lowercase and any spaces between them removed. This is done in order to ensure that the first names of any name, such as "Nancy", are not confused by the system. That way, our vectorizer does not confuse "Nancy Brown" and "Nancy Mitchell". I created the metadata soup, which included all the metadata I wanted to provide to the vectorizer (namely, the names of actors, director, and keywords).

The steps for creating this improved recommender were identical to those using the plot description-based recommender. I used CountVectorizer() instead of TF-IDF, which was a significant difference. This is because I didn't want to underestimate the existence of the actor or director just because the actor or director appeared or directed more movies. By providing a new cosine_sim2 matrix as a second input, I was able to reuse my get_recommendations() function:

```
get_recommendations('Inception', cosine_sim2)
```
![get_recommendations('Inception', cosine_sim2)](/images/movie/movie11.jpg)

```
get_recommendations('The Godfather', cosine_sim2)
```

![get_recommendations('The Godfather', cosine_sim2)](/images/movie/movie12.jpg)

The increased metadata has allowed our recommender to gather more information and provide us with better recommendations as seen for the Inception and The Godfather movies. 

<a id="ch6"></a>
# Step 4: Collaborative Filtering

![Collaborative Filtering](/images/movie/movie13.jpg)

Collaborative filtering is one of the powerful personalization technologies used on the adaptive web. Collaborative filtering is the process of filtering or evaluating items through the opinions of other people. CF technology lets communities of web users share their opinions on large amounts of data, helping to reduce the amount of information that needs to be processed. [Paper by Schafer et al. on Collaborative Filtering Recommender Systems can be found here.](https://link.springer.com/chapter/10.1007/978-3-540-72079-9_9)

Content-based engine which was discussed above has some significant limitations. It is only able to suggest movies which are similar to a certain movie. It is not able to provide recommendations across genres. Our engine does not take into account the personal preferences of a user, so anyone querying our engine for recommendations based on a movie will receive the same recommendations for that movie.

In this part, I used a technique called collaborative filtering to make recommendations to movie watchers. By pooling the data from multiple users, I was able to create a more accurate list of movies that may be of interest. There are two main types of filtering, user-based and item-based.

In a user-based recommendation system, the system recommends products to a user who is similar to others who have already liked those products. Although user-based CF is easy to implement, it has a number of shortcomings. One of the main problems with user preferences is that they can change over time. It may not be a good idea to precompute the matrix based on the neighboring users' data. We can use item-based CF to tackle this problem.

In Item-Based Collaborative Filtering, similarity is measured between items, not between users. The CF uses user ratings to recommend items that are similar to the items that the target user rated. Item-based CF is more static, so you can successfully avoid dynamic user-configured issues. The main problem with this system is that it is not able to handle large number of users and products.The computation expense increases as the number of users and products increase. The data may be too sparse to draw any meaningful conclusions.

Now we have the scalability and the sparsity issue. What do we do next? We can use a latent factor model to capture similarities between users and items. The optimization model would be as good as its ability to predict ratings for items when the user is the input. The success criterion would be the lowest possible RMSE value.

Latent factors can be defined as properties or concepts that are exhibited by either users or items. For example, in music, the latent factor may relate to the genre to which the music belongs. We map each user and each item into a latent space with a dimension r. This makes it easier to understand the relationship between users and items as they are compared directly.

![SVD](/images/movie/movie14.jpg)

We can use another dataset with userId if we want to do collaborative filtering with SVD. Below we can see the first 10 movies rated on a scale of 5. I will show the data for userId = 5, but there is data for all users in this dataset. I leveraged the Surprise library in the code below. To learn more: [see the Surprise documentation.](https://surprise.readthedocs.io/en/stable/index.html)

```
from surprise import Reader, evaluate, Dataset, SVD
reader = Reader()
ratings = pd.read_csv('../input/the-movies-dataset/ratings_small.csv')
ratings[ratings['userId'] == 5].head(10)
```

![SVD dataset](/images/movie/movie15.jpg)

Then I will make a prediction for userID = 5, and movieID = 356:

```
svd.predict(5, 356, 4)
```

Prediction(uid=5, iid=356, r_ui=4, est=4.1839714326949125, details={'was_impossible': False})

For the movie with ID 356, we predict it will have a rating of **4.18**. Recommender system doesn't care what the movie is. The rating prediction algorithm is based on a user's assigned movie ID, and it tries to guess how other users rated the movie.

There are recommendation engines out there which are recommending content to others based on its demographic, content, and collaborative filtering features. While demographic filtering is easy to use, it's not always possible or practical. Hybrid systems can use content-based and collaborative filtering to improve their recommendation engines. This project helped me learn about filtering techniques, and future work can focus on improving the algorithm.

<a id="ch90"></a>
# References
Thank you for the following resources I found helpful: 

* [Kaggle: Getting Started with a Movie Recommendation System](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata) 
* [Recommender Systems: Types of Filtering Techniques](https://www.ijert.org/research/recommender-systems-types-of-filtering-techniques-IJERTV3IS110197.pdf)
* [A Taxonomy of Recommender Agents on the Internet](https://link.springer.com/article/10.1023/A:1022850703159)
* [Information Filtering and Information Retrieval: Two Sides of the Same Coin?](https://dl.acm.org/doi/abs/10.1145/138859.138861)
* [Syskill & Webert: Identifying interesting web sites](https://www.aaai.org/Papers/Symposia/Spring/1996/SS-96-05/SS96-05-010.pdf)
* [Collaborative Filtering Recommender Systems](https://link.springer.com/chapter/10.1007/978-3-540-72079-9_9)
* [Surprise documentation](https://surprise.readthedocs.io/en/stable/index.html)





